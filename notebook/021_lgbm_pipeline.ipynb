{"cells":[{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-01-28T16:11:44.303818Z","iopub.status.busy":"2022-01-28T16:11:44.303377Z","iopub.status.idle":"2022-01-28T16:11:46.356508Z","shell.execute_reply":"2022-01-28T16:11:46.355585Z","shell.execute_reply.started":"2022-01-28T16:11:44.303709Z"},"trusted":true},"outputs":[],"source":["import os\n","import random\n","import pandas as pd\n","import numpy as np\n","import lightgbm as lgbm\n","import mlflow\n","\n","import sys\n","sys.path.append('../input/g-research-crypto-forecasting')\n","import gresearch_crypto\n","\n","\n","TRAIN_CSV = '../input/g-research-crypto-forecasting/train.csv'\n","ASSET_DETAILS_CSV = '../input/g-research-crypto-forecasting/asset_details.csv'\n","RESULT_FOLDER = '../result/nb021'\n","if not os.path.isdir(RESULT_FOLDER):\n","    os.makedirs(RESULT_FOLDER)\n","SEED = 2021\n","DEBUG = False\n","\n","REMOVE_LB_TEST_OVERLAPPING_DATA = True\n"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2022-01-28T16:11:46.358826Z","iopub.status.busy":"2022-01-28T16:11:46.358485Z","iopub.status.idle":"2022-01-28T16:11:46.364326Z","shell.execute_reply":"2022-01-28T16:11:46.363545Z","shell.execute_reply.started":"2022-01-28T16:11:46.358785Z"},"trusted":true},"outputs":[],"source":["def fix_all_seeds(seed):\n","    np.random.seed(seed)\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","\n","fix_all_seeds(SEED)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2022-01-28T16:11:46.365966Z","iopub.status.busy":"2022-01-28T16:11:46.365679Z","iopub.status.idle":"2022-01-28T16:11:46.491640Z","shell.execute_reply":"2022-01-28T16:11:46.490203Z","shell.execute_reply.started":"2022-01-28T16:11:46.365922Z"},"trusted":true},"outputs":[],"source":["def reduce_mem_usage(df, verbose=True):\n","    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n","    start_mem = df.memory_usage().sum() / 1024**2 \n","    dfs = []\n","    for col in df.columns:\n","        col_type = df[col].dtypes\n","        if col_type in numerics:\n","            c_min = df[col].min()\n","            c_max = df[col].max()\n","            if str(col_type)[:3] == 'int':\n","                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n","                    dfs.append(df[col].astype(np.int8))\n","                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n","                    dfs.append(df[col].astype(np.int16))\n","                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n","                    dfs.append(df[col].astype(np.int32))\n","                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n","                    dfs.append(df[col].astype(np.int64) ) \n","            else:\n","                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n","                    dfs.append(df[col].astype(np.float16))\n","                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n","                    dfs.append(df[col].astype(np.float32))\n","                else:\n","                    dfs.append(df[col].astype(np.float64))\n","        else:\n","            dfs.append(df[col])\n","    \n","    df_out = pd.concat(dfs, axis=1)\n","    if verbose:\n","        end_mem = df_out.memory_usage().sum() / 1024**2\n","        num_reduction = str(100 * (start_mem - end_mem) / start_mem)\n","        print(f'Mem. usage decreased to {str(end_mem)[:3]}Mb:  {num_reduction[:2]}% reduction')\n","    return df_out"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.status.busy":"2022-01-28T16:11:46.492755Z","iopub.status.idle":"2022-01-28T16:11:46.493261Z","shell.execute_reply":"2022-01-28T16:11:46.493102Z","shell.execute_reply.started":"2022-01-28T16:11:46.493082Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>timestamp</th>\n","      <th>Asset_ID</th>\n","      <th>Count</th>\n","      <th>Open</th>\n","      <th>High</th>\n","      <th>Low</th>\n","      <th>Close</th>\n","      <th>Volume</th>\n","      <th>VWAP</th>\n","      <th>Target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1514764860</td>\n","      <td>2</td>\n","      <td>40.0</td>\n","      <td>2376.5800</td>\n","      <td>2399.5000</td>\n","      <td>2357.1400</td>\n","      <td>2374.5900</td>\n","      <td>19.233005</td>\n","      <td>2373.116392</td>\n","      <td>-0.004218</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1514764860</td>\n","      <td>0</td>\n","      <td>5.0</td>\n","      <td>8.5300</td>\n","      <td>8.5300</td>\n","      <td>8.5300</td>\n","      <td>8.5300</td>\n","      <td>78.380000</td>\n","      <td>8.530000</td>\n","      <td>-0.014399</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1514764860</td>\n","      <td>1</td>\n","      <td>229.0</td>\n","      <td>13835.1940</td>\n","      <td>14013.8000</td>\n","      <td>13666.1100</td>\n","      <td>13850.1760</td>\n","      <td>31.550062</td>\n","      <td>13827.062093</td>\n","      <td>-0.014643</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1514764860</td>\n","      <td>5</td>\n","      <td>32.0</td>\n","      <td>7.6596</td>\n","      <td>7.6596</td>\n","      <td>7.6567</td>\n","      <td>7.6576</td>\n","      <td>6626.713370</td>\n","      <td>7.657713</td>\n","      <td>-0.013922</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1514764860</td>\n","      <td>7</td>\n","      <td>5.0</td>\n","      <td>25.9200</td>\n","      <td>25.9200</td>\n","      <td>25.8740</td>\n","      <td>25.8770</td>\n","      <td>121.087310</td>\n","      <td>25.891363</td>\n","      <td>-0.008264</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    timestamp  Asset_ID  Count        Open        High         Low  \\\n","0  1514764860         2   40.0   2376.5800   2399.5000   2357.1400   \n","1  1514764860         0    5.0      8.5300      8.5300      8.5300   \n","2  1514764860         1  229.0  13835.1940  14013.8000  13666.1100   \n","3  1514764860         5   32.0      7.6596      7.6596      7.6567   \n","4  1514764860         7    5.0     25.9200     25.9200     25.8740   \n","\n","        Close       Volume          VWAP    Target  \n","0   2374.5900    19.233005   2373.116392 -0.004218  \n","1      8.5300    78.380000      8.530000 -0.014399  \n","2  13850.1760    31.550062  13827.062093 -0.014643  \n","3      7.6576  6626.713370      7.657713 -0.013922  \n","4     25.8770   121.087310     25.891363 -0.008264  "]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["df_train = pd.read_csv(TRAIN_CSV)\n","df_train.head()"]},{"cell_type":"markdown","metadata":{},"source":["## Keep only values _before_ the LB test set"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.status.busy":"2022-01-28T16:11:46.494289Z","iopub.status.idle":"2022-01-28T16:11:46.494786Z","shell.execute_reply":"2022-01-28T16:11:46.494636Z","shell.execute_reply.started":"2022-01-28T16:11:46.494616Z"},"trusted":true},"outputs":[],"source":["# Remove the future\n","if REMOVE_LB_TEST_OVERLAPPING_DATA:\n","    df_train['datetime'] = pd.to_datetime(df_train['timestamp'], unit='s')\n","    df_test = df_train[df_train['datetime'] >= '2021-06-13 00:00:00']\n","    df_test = df_test.dropna(how=\"any\")\n","    df_train = df_train[df_train['datetime'] < '2021-06-13 00:00:00']\n","    if DEBUG:\n","        df_train = df_train.iloc[:100000]\n"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.status.busy":"2022-01-28T16:11:46.495764Z","iopub.status.idle":"2022-01-28T16:11:46.496228Z","shell.execute_reply":"2022-01-28T16:11:46.496083Z","shell.execute_reply.started":"2022-01-28T16:11:46.496065Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Asset_ID</th>\n","      <th>Weight</th>\n","      <th>Asset_Name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>4.304065</td>\n","      <td>Binance Coin</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>6.779922</td>\n","      <td>Bitcoin</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>2</td>\n","      <td>2.397895</td>\n","      <td>Bitcoin Cash</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>3</td>\n","      <td>4.406719</td>\n","      <td>Cardano</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>4</td>\n","      <td>3.555348</td>\n","      <td>Dogecoin</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5</td>\n","      <td>1.386294</td>\n","      <td>EOS.IO</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>6</td>\n","      <td>5.894403</td>\n","      <td>Ethereum</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>7</td>\n","      <td>2.079442</td>\n","      <td>Ethereum Classic</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>8</td>\n","      <td>1.098612</td>\n","      <td>IOTA</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>9</td>\n","      <td>2.397895</td>\n","      <td>Litecoin</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>10</td>\n","      <td>1.098612</td>\n","      <td>Maker</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>11</td>\n","      <td>1.609438</td>\n","      <td>Monero</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>12</td>\n","      <td>2.079442</td>\n","      <td>Stellar</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>13</td>\n","      <td>1.791759</td>\n","      <td>TRON</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    Asset_ID    Weight        Asset_Name\n","1          0  4.304065      Binance Coin\n","2          1  6.779922           Bitcoin\n","0          2  2.397895      Bitcoin Cash\n","10         3  4.406719           Cardano\n","13         4  3.555348          Dogecoin\n","3          5  1.386294            EOS.IO\n","5          6  5.894403          Ethereum\n","4          7  2.079442  Ethereum Classic\n","11         8  1.098612              IOTA\n","6          9  2.397895          Litecoin\n","12        10  1.098612             Maker\n","7         11  1.609438            Monero\n","9         12  2.079442           Stellar\n","8         13  1.791759              TRON"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["df_asset_details = pd.read_csv(ASSET_DETAILS_CSV).sort_values(\"Asset_ID\")\n","df_asset_details"]},{"cell_type":"markdown","metadata":{},"source":["# Training"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.status.busy":"2022-01-28T16:11:46.497146Z","iopub.status.idle":"2022-01-28T16:11:46.497632Z","shell.execute_reply":"2022-01-28T16:11:46.497469Z","shell.execute_reply.started":"2022-01-28T16:11:46.497451Z"},"trusted":true},"outputs":[],"source":["# !pip install --no-index --find-links ../input/talibbinary/talib_binary-0.4.19-cp37-cp37m-manylinux1_x86_64.whl talib-binary"]},{"cell_type":"markdown","metadata":{},"source":["## Utility functions to train a model for one asset"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.status.busy":"2022-01-28T16:11:46.498627Z","iopub.status.idle":"2022-01-28T16:11:46.499091Z","shell.execute_reply":"2022-01-28T16:11:46.498940Z","shell.execute_reply.started":"2022-01-28T16:11:46.498922Z"},"trusted":true},"outputs":[],"source":["import talib\n","from sklearn.preprocessing import StandardScaler\n","sys.path.append('../src')\n","from utils import eval_w_corr\n","\n","# Two new features from the competition tutorial\n","def upper_shadow(df):\n","    return df['High'] - np.maximum(df['Close'], df['Open'])\n","\n","def lower_shadow(df):\n","    return np.minimum(df['Close'], df['Open']) - df['Low']\n","\n","def moving_average(a, n):\n","    ret = np.cumsum(a, dtype=float)\n","    ret[n:] = ret[n:] - ret[:-n]\n","    return ret / n\n","\n","# A utility function to build features from the original df\n","# It works for rows to, so we can reutilize it.\n","def get_features(df):\n","    df_feat = df[['Count', 'Open', 'High', 'Low', 'Close', 'Volume', 'VWAP', 'Asset_ID', 'Target', 'timestamp']].copy()\n","    weight_map_dict = dict(zip(df_asset_details['Asset_ID'], df_asset_details['Weight']))\n","    df_feat['Weight'] = df_feat['Asset_ID'].map(weight_map_dict)\n","\n","    df_feat['upper_shadow'] = upper_shadow(df_feat)\n","    df_feat['lower_shadow'] = lower_shadow(df_feat)\n","    \n","    df_feat['ln_Close'] = np.log(df['Close'])\n","    \n","    asset_group_close = df_feat.groupby('Asset_ID')['Close']\n","\n","    df_feat['high_low_div'] = df_feat['High'] / df_feat['Low']\n","    df_feat['open_close_div'] = df_feat['Open'] / df_feat['Close']\n","\n","    df_feat['hlco_ration'] = (df_feat[\"Open\"] - df_feat[\"Close\"]) / (df_feat[\"High\"] - df_feat[\"Low\"])\n","    \n","    df_feat['log_return_1'] = df_feat['ln_Close'] - df_feat.groupby('Asset_ID')['ln_Close'].shift(1)\n","    df_feat['log_return_5'] = df_feat['ln_Close'] - df_feat.groupby('Asset_ID')['ln_Close'].shift(5)\n","    df_feat['log_return_15'] = df_feat['ln_Close'] - df_feat.groupby('Asset_ID')['ln_Close'].shift(15)\n","    df_feat['log_return_60'] = df_feat['ln_Close'] - df_feat.groupby('Asset_ID')['ln_Close'].shift(60)\n","    \n","    for i in [5, 15, 60]:\n","        df_feat['realized_volatility_'+str(i)] = df_feat.groupby('Asset_ID').log_return_1.transform(lambda x: x.rolling(i).std(ddof=0))\n","#         df_data['RV_'+str(i)+'_rank'] = df_data.groupby('timestamp')['realized_volatility_'+str(i)].transform('rank')\n","    \n","        df_feat['moving_average_'+str(i)] = asset_group_close.transform(lambda x: moving_average(x.values, i))\n","        df_feat['moving_std_'+str(i)] = asset_group_close.transform(lambda x: x.rolling(window=i, min_periods=1).std())\n","        df_feat['volume_moving_average_'+str(i)] = df_feat.groupby('Asset_ID').Volume.transform(lambda x: moving_average(x.values, i))\n","        df_feat['RSI_'+str(i)] = asset_group_close.transform(lambda x: talib.RSI(x.values.astype(np.float64), i))\n","        \n","        df_feat['close_div_ma_'+str(i)] = df_feat['Close'] / df_feat['moving_average_'+str(i)]\n","        df_feat['volume_div_ma_'+str(i)] = df_feat['Volume'] / df_feat['volume_moving_average_'+str(i)]\n","        df_feat['RV_'+str(i)+'_rank'] = df_feat.groupby('timestamp')['realized_volatility_'+str(i)].transform('rank')\n","\n","    # df_feat['MACD'], df_feat['MACD_signal'], df_feat['MACD_hist'] = talib.MACD(df_feat.Close.values, fastperiod=12, slowperiod=26, signalperiod=9)\n","    # df_feat['adx'] = talib.ADX(df_feat.High, df_feat.Low, df_feat.Close, timeperiod=14)\n","\n","    df_feat['close_div_ma_5'] = df_feat['Close'] / df_feat['moving_average_5']\n","    df_feat['close_div_ma_15'] = df_feat['Close'] / df_feat['moving_average_15']\n","    df_feat['close_div_ma_60'] = df_feat['Close'] / df_feat['moving_average_60']\n","\n","    df_feat['volume_div_ma_5'] = df_feat['Volume'] / df_feat['volume_moving_average_5']\n","    df_feat['volume_div_ma_15'] = df_feat['Volume'] / df_feat['volume_moving_average_15']\n","    df_feat['volume_div_ma_60'] = df_feat['Volume'] / df_feat['volume_moving_average_60']\n","\n","    df_feat['close_div_ma_15_rank'] = df_feat.groupby('timestamp').close_div_ma_15.transform('rank')\n","    df_feat['volume_div_ma_15_rank'] = df_feat.groupby('timestamp').volume_div_ma_15.transform('rank')\n","\n","    df_feat['RSI_5_rank'] = df_feat.groupby('timestamp').RSI_5.transform('rank')\n","    df_feat['RSI_15_rank'] = df_feat.groupby('timestamp').RSI_15.transform('rank')\n","    df_feat['RSI_60_rank'] = df_feat.groupby('timestamp').RSI_60.transform('rank')\n","\n","    inv_weight_sum = 1.0 / df_feat.groupby('timestamp')['Weight'].transform('sum')\n","    \n","    df_feat['w_log_return_15'] = df_feat['log_return_15'] * df_feat['Weight']\n","    df_feat['market_return_causal'] = df_feat.groupby('timestamp').w_log_return_15.transform('sum') * inv_weight_sum\n","    \n","    df_feat['raw_market_return_causal'] = df_feat['log_return_15'] * df_feat['market_return_causal']\n","    df_feat['market_return_causal_square'] = df_feat['market_return_causal'] ** 2\n","    df_feat['beta_causal'] = (\n","        df_feat.groupby('Asset_ID').raw_market_return_causal.transform(lambda x: moving_average(x.fillna(0).values, 60))\n","        / df_feat.groupby('Asset_ID').market_return_causal_square.transform(lambda x: moving_average(x.fillna(0).values, 60))\n","    )\n","\n","    df_feat['Close_diff1_rank'] = df_feat.groupby('timestamp')['log_return_15'].transform('rank')\n","\n","    df_feat = df_feat.drop(['ln_Close', 'timestamp'], axis=1)\n","    \n","    return df_feat\n","\n","\n","def get_model_for_asset(df_train, df_test, asset_id):\n","    df_train = df_train[df_train[\"Asset_ID\"] == asset_id]\n","    df_test = df_test[df_test[\"Asset_ID\"] == asset_id]\n","    \n","    df_train = df_train.dropna(how=\"any\")\n","    df_test = df_test.dropna(how=\"any\")\n","\n","    \n","    X_train, y_train = df_train.drop(['Asset_ID', 'Target'], axis=1), df_train[\"Target\"]\n","    X_valid, y_valid = df_test.drop(['Asset_ID', 'Target'], axis=1), df_test[\"Target\"]\n","    lgbm_train = lgbm.Dataset(X_train, y_train)\n","    lgbm_valid = lgbm.Dataset(X_valid, y_valid)\n","    weight_map_dict = dict(zip(df_asset_details['Asset_ID'], df_asset_details['Weight']))\n","    lgbm_train.add_w = df_train['Asset_ID'].map(weight_map_dict)\n","    lgbm_valid.add_w = df_test['Asset_ID'].map(weight_map_dict)\n","    with mlflow.start_run(experiment_id=5, nested=True):\n","\n","        params = {\n","            \"objective\": \"regression\", \n","            \"metric\": \"rsme\", \n","            \"boosting_type\": \"gbdt\",\n","            # 'early_stopping_rounds': 20,\n","            'learning_rate': 0.05,\n","            'num_leaves': 8,\n","            'feature_fraction': 0.5,\n","            'bagging_fraction': 0.5,\n","            'bagging_freq': 1,\n","            # 'extra_trees': True,\n","            'seed': 55\n","        }\n","        mlflow.log_params(params)\n","        mlflow.log_param('Asset_ID', asset_id)\n","\n","        category_feature = []\n","        model = lgbm.train(params=params,\n","            train_set=lgbm_train,\n","            valid_sets=[lgbm_train, lgbm_valid],\n","            num_boost_round=50,\n","            verbose_eval=10,\n","            feval=eval_w_corr,\n","            categorical_feature = category_feature,\n","        )\n","    \n","    return model"]},{"cell_type":"markdown","metadata":{},"source":["## Loop over all assets"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.status.busy":"2022-01-28T16:11:46.499993Z","iopub.status.idle":"2022-01-28T16:11:46.500457Z","shell.execute_reply":"2022-01-28T16:11:46.500307Z","shell.execute_reply.started":"2022-01-28T16:11:46.500289Z"},"trusted":true},"outputs":[],"source":["def weighted_correlation(a, b, weights):\n","  w = np.ravel(weights)\n","  a = np.ravel(a)\n","  b = np.ravel(b)\n","\n","  sum_w = np.sum(w)\n","  mean_a = np.sum(a * w) / sum_w\n","  mean_b = np.sum(b * w) / sum_w\n","  var_a = np.sum(w * np.square(a - mean_a)) / sum_w\n","  var_b = np.sum(w * np.square(b - mean_b)) / sum_w\n","\n","  cov = np.sum((a * b * w)) / np.sum(w) - mean_a * mean_b\n","  corr = cov / np.sqrt(var_a * var_b)\n","\n","  return corr"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Index(['Count', 'Open', 'High', 'Low', 'Close', 'Volume', 'VWAP', 'Asset_ID',\n","       'Target', 'Weight', 'upper_shadow', 'lower_shadow', 'high_low_div',\n","       'open_close_div', 'hlco_ration', 'log_return_1', 'log_return_5',\n","       'log_return_15', 'log_return_60', 'realized_volatility_5',\n","       'moving_average_5', 'moving_std_5', 'volume_moving_average_5', 'RSI_5',\n","       'close_div_ma_5', 'volume_div_ma_5', 'RV_5_rank',\n","       'realized_volatility_15', 'moving_average_15', 'moving_std_15',\n","       'volume_moving_average_15', 'RSI_15', 'close_div_ma_15',\n","       'volume_div_ma_15', 'RV_15_rank', 'realized_volatility_60',\n","       'moving_average_60', 'moving_std_60', 'volume_moving_average_60',\n","       'RSI_60', 'close_div_ma_60', 'volume_div_ma_60', 'RV_60_rank',\n","       'close_div_ma_15_rank', 'volume_div_ma_15_rank', 'RSI_5_rank',\n","       'RSI_15_rank', 'RSI_60_rank', 'w_log_return_15', 'market_return_causal',\n","       'raw_market_return_causal', 'market_return_causal_square',\n","       'beta_causal', 'Close_diff1_rank'],\n","      dtype='object')\n"]}],"source":["\n","df_train = get_features(df_train)\n","df_test = get_features(df_test)\n","print(df_train.columns)"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.status.busy":"2022-01-28T16:11:46.501391Z","iopub.status.idle":"2022-01-28T16:11:46.501961Z","shell.execute_reply":"2022-01-28T16:11:46.501758Z","shell.execute_reply.started":"2022-01-28T16:11:46.501729Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Training model for Binance Coin     (ID=0 )\n"]},{"name":"stderr","output_type":"stream","text":["/home/yoshikawa/.pyenv/versions/3.7.10/envs/g_research_crypto/lib/python3.7/site-packages/lightgbm/basic.py:2068: UserWarning: categorical_feature in Dataset is overridden.\n","New categorical_feature is []\n","  _log_warning('categorical_feature in Dataset is overridden.\\n'\n","/home/yoshikawa/.pyenv/versions/3.7.10/envs/g_research_crypto/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"]},{"name":"stdout","output_type":"stream","text":["[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.196738 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 10846\n","[LightGBM] [Info] Number of data points in the train set: 1765347, number of used features: 51\n","[LightGBM] [Info] Start training from score 0.000034\n","[10]\ttraining's eval_wcorr: 0.163224\tvalid_1's eval_wcorr: 0.02645\n","[20]\ttraining's eval_wcorr: 0.180645\tvalid_1's eval_wcorr: 0.0442006\n","[30]\ttraining's eval_wcorr: 0.190104\tvalid_1's eval_wcorr: 0.0291826\n","[40]\ttraining's eval_wcorr: 0.198543\tvalid_1's eval_wcorr: -0.0112814\n","[50]\ttraining's eval_wcorr: 0.202401\tvalid_1's eval_wcorr: -0.00225253\n","Training model for Bitcoin          (ID=1 )\n","[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.230028 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 10845\n","[LightGBM] [Info] Number of data points in the train set: 1811892, number of used features: 51\n","[LightGBM] [Info] Start training from score -0.000002\n","[10]\ttraining's eval_wcorr: 0.105925\tvalid_1's eval_wcorr: 0.0360127\n","[20]\ttraining's eval_wcorr: 0.11694\tvalid_1's eval_wcorr: 0.0438866\n","[30]\ttraining's eval_wcorr: 0.132543\tvalid_1's eval_wcorr: 0.0539612\n","[40]\ttraining's eval_wcorr: 0.145\tvalid_1's eval_wcorr: 0.0520104\n","[50]\ttraining's eval_wcorr: 0.154725\tvalid_1's eval_wcorr: 0.039684\n","Training model for Bitcoin Cash     (ID=2 )\n","[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.237452 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 10847\n","[LightGBM] [Info] Number of data points in the train set: 1798481, number of used features: 51\n","[LightGBM] [Info] Start training from score -0.000006\n","[10]\ttraining's eval_wcorr: 0.129798\tvalid_1's eval_wcorr: -0.00271681\n","[20]\ttraining's eval_wcorr: 0.151506\tvalid_1's eval_wcorr: 0.0273604\n","[30]\ttraining's eval_wcorr: 0.174913\tvalid_1's eval_wcorr: 0.038801\n","[40]\ttraining's eval_wcorr: 0.187875\tvalid_1's eval_wcorr: 0.035362\n","[50]\ttraining's eval_wcorr: 0.202565\tvalid_1's eval_wcorr: 0.0350838\n","Training model for Cardano          (ID=3 )\n","[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.206911 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 10846\n","[LightGBM] [Info] Number of data points in the train set: 1613253, number of used features: 51\n","[LightGBM] [Info] Start training from score -0.000000\n","[10]\ttraining's eval_wcorr: 0.0995412\tvalid_1's eval_wcorr: 0.0604088\n","[20]\ttraining's eval_wcorr: 0.110532\tvalid_1's eval_wcorr: 0.0559576\n","[30]\ttraining's eval_wcorr: 0.115433\tvalid_1's eval_wcorr: 0.0640548\n","[40]\ttraining's eval_wcorr: 0.119995\tvalid_1's eval_wcorr: 0.0660108\n","[50]\ttraining's eval_wcorr: 0.126403\tvalid_1's eval_wcorr: 0.0673894\n","Training model for Dogecoin         (ID=4 )\n","[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.160018 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 10857\n","[LightGBM] [Info] Number of data points in the train set: 752214, number of used features: 51\n","[LightGBM] [Info] Start training from score 0.000063\n","[10]\ttraining's eval_wcorr: 0.182162\tvalid_1's eval_wcorr: 0.0675333\n","[20]\ttraining's eval_wcorr: 0.217194\tvalid_1's eval_wcorr: 0.0598581\n","[30]\ttraining's eval_wcorr: 0.237649\tvalid_1's eval_wcorr: 0.0673514\n","[40]\ttraining's eval_wcorr: 0.262591\tvalid_1's eval_wcorr: 0.0771408\n","[50]\ttraining's eval_wcorr: 0.275075\tvalid_1's eval_wcorr: 0.0780109\n","Training model for EOS.IO           (ID=5 )\n","[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.238800 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 10845\n","[LightGBM] [Info] Number of data points in the train set: 1805357, number of used features: 51\n","[LightGBM] [Info] Start training from score -0.000001\n","[10]\ttraining's eval_wcorr: 0.107612\tvalid_1's eval_wcorr: 0.0624173\n","[20]\ttraining's eval_wcorr: 0.121379\tvalid_1's eval_wcorr: 0.0587076\n","[30]\ttraining's eval_wcorr: 0.129646\tvalid_1's eval_wcorr: 0.0674642\n","[40]\ttraining's eval_wcorr: 0.139862\tvalid_1's eval_wcorr: 0.0683677\n","[50]\ttraining's eval_wcorr: 0.150812\tvalid_1's eval_wcorr: 0.0705037\n","Training model for Ethereum         (ID=6 )\n","[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.241670 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 10845\n","[LightGBM] [Info] Number of data points in the train set: 1811744, number of used features: 51\n","[LightGBM] [Info] Start training from score -0.000002\n","[10]\ttraining's eval_wcorr: 0.105171\tvalid_1's eval_wcorr: 0.038441\n","[20]\ttraining's eval_wcorr: 0.112306\tvalid_1's eval_wcorr: 0.0424336\n","[30]\ttraining's eval_wcorr: 0.118507\tvalid_1's eval_wcorr: 0.0437168\n","[40]\ttraining's eval_wcorr: 0.124586\tvalid_1's eval_wcorr: 0.0434973\n","[50]\ttraining's eval_wcorr: 0.131175\tvalid_1's eval_wcorr: 0.0424456\n","Training model for Ethereum Classic (ID=7 )\n","[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.270364 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 10845\n","[LightGBM] [Info] Number of data points in the train set: 1785567, number of used features: 51\n","[LightGBM] [Info] Start training from score 0.000042\n","[10]\ttraining's eval_wcorr: 0.0783958\tvalid_1's eval_wcorr: 0.0538967\n","[20]\ttraining's eval_wcorr: 0.0854825\tvalid_1's eval_wcorr: 0.0604918\n","[30]\ttraining's eval_wcorr: 0.0921347\tvalid_1's eval_wcorr: 0.069641\n","[40]\ttraining's eval_wcorr: 0.0974363\tvalid_1's eval_wcorr: 0.0694682\n","[50]\ttraining's eval_wcorr: 0.102281\tvalid_1's eval_wcorr: 0.07029\n","Training model for IOTA             (ID=8 )\n","[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.193276 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 10856\n","[LightGBM] [Info] Number of data points in the train set: 1152350, number of used features: 51\n","[LightGBM] [Info] Start training from score 0.000015\n","[10]\ttraining's eval_wcorr: 0.132372\tvalid_1's eval_wcorr: -0.00224017\n","[20]\ttraining's eval_wcorr: 0.146735\tvalid_1's eval_wcorr: -0.0031333\n","[30]\ttraining's eval_wcorr: 0.159151\tvalid_1's eval_wcorr: -0.000530437\n","[40]\ttraining's eval_wcorr: 0.165866\tvalid_1's eval_wcorr: 0.00237363\n","[50]\ttraining's eval_wcorr: 0.169501\tvalid_1's eval_wcorr: 0.000204765\n","Training model for Litecoin         (ID=9 )\n","[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.270862 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 10845\n","[LightGBM] [Info] Number of data points in the train set: 1810864, number of used features: 51\n","[LightGBM] [Info] Start training from score -0.000014\n","[10]\ttraining's eval_wcorr: 0.101805\tvalid_1's eval_wcorr: 0.0454652\n","[20]\ttraining's eval_wcorr: 0.11333\tvalid_1's eval_wcorr: 0.0321236\n","[30]\ttraining's eval_wcorr: 0.121391\tvalid_1's eval_wcorr: 0.0354309\n","[40]\ttraining's eval_wcorr: 0.128603\tvalid_1's eval_wcorr: 0.0334711\n","[50]\ttraining's eval_wcorr: 0.133812\tvalid_1's eval_wcorr: 0.0382638\n","Training model for Maker            (ID=10)\n","[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.121955 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 10845\n","[LightGBM] [Info] Number of data points in the train set: 476411, number of used features: 51\n","[LightGBM] [Info] Start training from score -0.000000\n","[10]\ttraining's eval_wcorr: 0.150159\tvalid_1's eval_wcorr: 0.0260131\n","[20]\ttraining's eval_wcorr: 0.186412\tvalid_1's eval_wcorr: 0.0394498\n","[30]\ttraining's eval_wcorr: 0.208435\tvalid_1's eval_wcorr: 0.0391204\n","[40]\ttraining's eval_wcorr: 0.220388\tvalid_1's eval_wcorr: 0.0366405\n","[50]\ttraining's eval_wcorr: 0.229401\tvalid_1's eval_wcorr: 0.0330046\n","Training model for Monero           (ID=11)\n","[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.209183 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 10855\n","[LightGBM] [Info] Number of data points in the train set: 1205282, number of used features: 51\n","[LightGBM] [Info] Start training from score 0.000006\n","[10]\ttraining's eval_wcorr: 0.13704\tvalid_1's eval_wcorr: -0.00859775\n","[20]\ttraining's eval_wcorr: 0.154027\tvalid_1's eval_wcorr: -0.0130164\n","[30]\ttraining's eval_wcorr: 0.162831\tvalid_1's eval_wcorr: -0.0175364\n","[40]\ttraining's eval_wcorr: 0.17098\tvalid_1's eval_wcorr: -0.00912564\n","[50]\ttraining's eval_wcorr: 0.177651\tvalid_1's eval_wcorr: -0.00390069\n","Training model for Stellar          (ID=12)\n","[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.223720 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 10846\n","[LightGBM] [Info] Number of data points in the train set: 1548076, number of used features: 51\n","[LightGBM] [Info] Start training from score -0.000010\n","[10]\ttraining's eval_wcorr: 0.123184\tvalid_1's eval_wcorr: 0.0633163\n","[20]\ttraining's eval_wcorr: 0.133993\tvalid_1's eval_wcorr: 0.0679488\n","[30]\ttraining's eval_wcorr: 0.145619\tvalid_1's eval_wcorr: 0.0759331\n","[40]\ttraining's eval_wcorr: 0.15459\tvalid_1's eval_wcorr: 0.077414\n","[50]\ttraining's eval_wcorr: 0.159457\tvalid_1's eval_wcorr: 0.0752133\n","Training model for TRON             (ID=13)\n","[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.277047 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 10850\n","[LightGBM] [Info] Number of data points in the train set: 1701513, number of used features: 51\n","[LightGBM] [Info] Start training from score 0.000008\n","[10]\ttraining's eval_wcorr: 0.114057\tvalid_1's eval_wcorr: 0.0442858\n","[20]\ttraining's eval_wcorr: 0.12484\tvalid_1's eval_wcorr: 0.0216796\n","[30]\ttraining's eval_wcorr: 0.139507\tvalid_1's eval_wcorr: 0.0442784\n","[40]\ttraining's eval_wcorr: 0.146442\tvalid_1's eval_wcorr: 0.063337\n","[50]\ttraining's eval_wcorr: 0.159899\tvalid_1's eval_wcorr: 0.0825924\n","overall, wcorr: 0.040456936011489926\n"]}],"source":["Xs = {}\n","ys = {}\n","models = {}\n","\n","y_valids = []\n","mlflow.lightgbm.autolog()\n","mlflow.set_tracking_uri('../src/mlruns/')\n","with mlflow.start_run(experiment_id=5):\n","    for asset_id, asset_name in zip(df_asset_details['Asset_ID'], df_asset_details['Asset_Name']):\n","        print(f\"Training model for {asset_name:<16} (ID={asset_id:<2})\")\n","        \n","        model = get_model_for_asset(df_train, df_test, asset_id)\n","        models[asset_id] = model\n","        \n","        X_valid = df_test[df_test['Asset_ID'] == asset_id].drop(['Target', 'Asset_ID'], axis=1)\n","        y_valid = df_test.loc[df_test['Asset_ID'] == asset_id, ['Target']]\n","        weight_map_dict = dict(zip(df_asset_details['Asset_ID'], df_asset_details['Weight']))\n","        y_valid['Weight'] = weight_map_dict[asset_id]\n","        y_valid['Pred'] = model.predict(X_valid)\n","        \n","        y_valids.append(y_valid)\n","        model.save_model(os.path.join(RESULT_FOLDER, f'model{asset_id}.lgb'), num_iteration=model.best_iteration)\n","\n","    y_valids = pd.concat(y_valids)\n","\n","    metric = weighted_correlation(y_valids['Pred'], y_valids['Target'], y_valids['Weight'])\n","    print(f\"overall, wcorr: {metric}\")\n","    mlflow.log_metric('score', metric)\n","\n","del X_valid, y_valid, y_valids"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-01-28T16:11:46.502803Z","iopub.status.idle":"2022-01-28T16:11:46.503116Z","shell.execute_reply":"2022-01-28T16:11:46.502973Z","shell.execute_reply.started":"2022-01-28T16:11:46.502952Z"},"trusted":true},"outputs":[{"ename":"ValueError","evalue":"stop!","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_1340079/2431878494.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"stop!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mValueError\u001b[0m: stop!"]}],"source":["raise ValueError(\"stop!\")"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.status.busy":"2021-11-02T20:57:49.349459Z","iopub.status.idle":"2021-11-02T20:57:49.349757Z","shell.execute_reply":"2021-11-02T20:57:49.349613Z","shell.execute_reply.started":"2021-11-02T20:57:49.349596Z"}},"source":["# Predict & submit\n","\n","References: [Detailed API Introduction](https://www.kaggle.com/sohier/detailed-api-introduction)\n","\n","Something that helped me understand this iterator was adding a pdb checkpoint inside of the for loop:\n","\n","```python\n","import pdb; pdb.set_trace()\n","```\n","\n","See [Python Debugging With Pdb](https://realpython.com/python-debugging-pdb/) if you want to use it and you don't know how to.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-01-28T16:11:46.504287Z","iopub.status.idle":"2022-01-28T16:11:46.504618Z","shell.execute_reply":"2022-01-28T16:11:46.504453Z","shell.execute_reply.started":"2022-01-28T16:11:46.504431Z"},"trusted":true},"outputs":[],"source":["import time\n","history = pd.DataFrame()\n","max_lookback = 60\n","\n","env = gresearch_crypto.make_env()\n","iter_test = env.iter_test()\n","\n","start = time.time()\n","for i, (df_test, df_pred) in enumerate(iter_test):\n","    history = pd.concat([history, df_test]).reset_index(drop=True)\n","\n","    for j , row in df_test.iterrows():\n","        model = models[row['Asset_ID']]\n","        x_test = get_features(history[history['Asset_ID'] == row['Asset_ID']]).reset_index(drop=True)\n","        y_pred = model.predict([x_test.iloc[-1]])[0]\n","        \n","        df_pred.loc[df_pred['row_id'] == row['row_id'], 'Target'] = y_pred\n","        \n","        # Print just one sample row to get a feeling of what it looks like\n","        if i == 0 and j == 0:\n","            display(x_test)\n","\n","    # Display the first prediction dataframe\n","    if i == 0:\n","        display(df_pred)\n","    history = history.sort_values(by='row_id')\n","    history = history.iloc[-(max_lookback*14+100):]\n","    \n","    # Send submissions\n","    env.predict(df_pred)\n","end = time.time()\n","end-start"]},{"cell_type":"markdown","metadata":{},"source":["# df_train and df_test overlap"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-01-28T16:11:46.506071Z","iopub.status.idle":"2022-01-28T16:11:46.506395Z","shell.execute_reply":"2022-01-28T16:11:46.506248Z","shell.execute_reply.started":"2022-01-28T16:11:46.506218Z"},"trusted":true},"outputs":[],"source":["# df_test = pd.concat(all_df_test)\n","# df_test['datetime'] = pd.to_datetime(df_test['timestamp'], unit='s')\n","# df_train['datetime'] = pd.to_datetime(df_train['timestamp'], unit='s')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-01-28T16:11:46.507943Z","iopub.status.idle":"2022-01-28T16:11:46.508481Z","shell.execute_reply":"2022-01-28T16:11:46.508306Z","shell.execute_reply.started":"2022-01-28T16:11:46.508280Z"},"trusted":true},"outputs":[],"source":["# df_train['datetime'].max()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-01-28T16:11:46.509803Z","iopub.status.idle":"2022-01-28T16:11:46.510114Z","shell.execute_reply":"2022-01-28T16:11:46.509975Z","shell.execute_reply.started":"2022-01-28T16:11:46.509957Z"},"trusted":true},"outputs":[],"source":["# df_test['datetime'].min()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"}},"nbformat":4,"nbformat_minor":4}
